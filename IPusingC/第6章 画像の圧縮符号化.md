#動画像の圧縮符号化(p.81)

予測差分誤差: フレーム間の画像の誤差を予測する

符号化は mpeg 符号化法などが使われる。

##離散コサイン変換(p.82)

フレーム画像の圧縮は離散コサイン変換( Discrete Cosine Transform: DCT )の係数を保存する方法を用いる。コサイン関数がベース。離散フーリエ変換( Discrete Fourier Transform: DFT )よりも低周波成分に偏る。低周波成分に多くの情報量を割き、高周波成分は小さい情報量にする。

DCT処理手順

1.  8x8 程度の画素を正方形状ブロックに分割
1.  ブロックごとに DCT 実施
1.  係数を保存

#静止階調画像に対する可逆形圧縮符号化(p.83)

ランレングス符号化法。連続する同じ階調の画素の列(ラン)の長さを元にデータ圧縮をおこなう。

[連長圧縮 - Wikipedia](http://ja.wikipedia.org/wiki/%E9%80%A3%E9%95%B7%E5%9C%A7%E7%B8%AE)

> 「A A A A A B B B B B B B B B A A A」は「A 5 B 9 A 3」と表せる。これは、Aが5回続き、そのあとにBが9回、そしてAが3回続いていることを表している（連続回数を、元のデータを表す符号の前に記録することもある。その場合、符号化した後は「5 A 9 B 3 A」と表される）。

> 白と黒以外にほとんど情報がないモノクロファクシミリでよく使われている。

runlength.c

     1: 0+00 ==> 3
     2: 0+01 ==> 3
     3: 0+10 ==> 3
     4: 0+11 ==> 3
     5: 10+100 ==> 5
     6: 10+101 ==> 5
     7: 10+110 ==> 5
     8: 10+111 ==> 5
     9: 110+1000 ==> 7
    10: 110+1001 ==> 7
    11: 110+1010 ==> 7
    12: 110+1011 ==> 7
    13: 110+1100 ==> 7
    14: 110+1101 ==> 7
    15: 110+1110 ==> 7
    16: 110+1111 ==> 7
    17: 1110+10000 ==> 9
    18: 1110+10001 ==> 9
    19: 1110+10010 ==> 9
    20: 1110+10011 ==> 9
    21: 1110+10100 ==> 9
    22: 1110+10101 ==> 9
    23: 1110+10110 ==> 9
    24: 1110+10111 ==> 9
    25: 1110+11000 ==> 9
    26: 1110+11001 ==> 9
    27: 1110+11010 ==> 9
    28: 1110+11011 ==> 9
    29: 1110+11100 ==> 9
    30: 1110+11101 ==> 9
    31: 1110+11110 ==> 9
    32: 1110+11111 ==> 9
    33: 11110+100000 ==> 11


#静止階調画像に対する非可逆形圧縮符号化(p.84)

##JPEG 符号化法(p.84)

1.  8x8 程度の画素を正方形状ブロックに分割
1.  ブロックごとに DCT 実施
1.  係数を保存

直交変換の係数を利用する方式は効率の良いデータ圧縮を実現する。データ圧縮率を小さくしすぎると符号化の単位であるブロック状のノイズが目立つようになる。

##ベクトル量子化法(p.85)

ベクトル量子化法( Vector Quantization method: VQ法 )

1.  原画像を正方形のブロックに分割
1.  ブロックパターンを各軸の座標とみなして多次元空間中の座標に写像
1.  全ブロックをこの空間中の点として写像
1.  それらの点をクラスタリングしていくつかのクラスに分類
1.  クラスに属する全てのブロックをそのクラスを代表する点(代表ベクトル)のブロックパターンで表す


[東京大学工学部計数工学科応用音響学 D3 - ベクトル量子化](http://ocw.u-tokyo.ac.jp/wp-content/uploads/lecture-notes/Engin_01/D3-VectorQuantization.pdf) (PDF)

*  ベクトル量子化の意義・用途
       *  特徴ベクトルの時系列で表現される音声の符号化や認識などに広く利用される。
       *  音声認識、話者認識に用いられる。
       *  画像圧縮、画像符号化（jpeg等）にも用いられる。
       *  構造的パターン認識法の入力として使用できる。
       *  音声波形やパラメータの組には連続性や相関があり、それらをまとめて符号化することによって、独立に符号化するときよりも情報量を削減できる。
       *  波形の時系列や音声の特徴パラメータに適用され、ベクトルの低ビット表現化が可能であることから、主にデータ量の削減化法として用いられる。
       *  スカラ量子化や直交変換符号化に比べて無駄が少ない。

[ベクトル量子化　フリーウエアでのソースコード](http://staff.aist.go.jp/toru-nakata/VectorQuantization.html)


> 多次元で多数のデータを分類する統計手法です。

> データの間に存在する、法則性を見抜くことに使います。最近のデジタルカメラが、人の顔を認識できるのは、ベクトル量子化を使っているからです。（このように実用上は、主成分分析や、因子分析、ニューラルネットなどの類似の認識手法よりも、圧倒的に高性能です。高次元、非線形現象、多数データの分析においては、デファクトスタンダードと言えます。）

> 以前は、データを圧縮するための分類手法だったのですが、認識技法としても注目されるようになりました。

[ベクトル量子化 - デー](http://d.hatena.ne.jp/ultraist/20091128/1259424239)

    int クラスのヒストグラム[K] = { 0 };
    vector 特徴点;
    foreach 特徴点 (画像に含まれる特徴点たち) {
       int クラスラベル = ベクトル量子化(特徴点);
       ++クラスのヒストグラム[クラスラベル];
    }


vq.c (p.91)

関数 clustering() でブロックパターンのベクトル群を k-平均法( k-means method )というクラスタリング手法によってクラス分けして代表ベクトルを設定。k-平均法の手順はこう:

1.  ランダムに k 個のブロックパターンを選択し、k 個のクラスの代表ベクトルであるとみなす
1.  全てのブロックパターンについて、最も近い距離にある代表ベクトルを求め、コードブロック中にその代表ベクトルのクラス番号を書き込む
1.  各クラスについて、そのクラスに属す全てのべtクトルの重心の座標を求め、それをそのクラスを代表するベクトルであるとみなす。
1.  2 に戻って処理を繰り返す。もはや代表ベクトルが修正されなくなったら収束したとみなして処理を終了する

{{ref_image lena.png,FrontPage}}

元画像 64KB

{{ref_image vq.png}}

VQ圧縮後 64KB

圧縮されてないんだけど...?
